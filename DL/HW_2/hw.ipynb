{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bd5e617",
   "metadata": {},
   "source": [
    "# mipt_dl_captcha_2025\n",
    "\n",
    "Данные для обучения содержатся в двух файлах: `images.npy` и `labels.npy`. Это формат numpy-массивов.\n",
    "\n",
    "```#загрузка данных\n",
    "import numpy as np\n",
    "images = np.load('/kaggle/input/mipt-dl-captcha/data/images.npy')\n",
    "labels = np.load('/kaggle/input/mipt-dl-captcha/data/labels.npy')\n",
    "```  \n",
    "Всего доступно 20 тысяч размеченных изображений размером 48x48 с 3 цветовыми каналами (RGB), поэтому массив _images_ имеет размер (20000, 48, 48, 3). В массиве _labels_ содержатся ответы к тренировочному набору изображений. В английском алфавите 26 букв: 0-й класс соответствует букве А и так далее по алфавиту, 25-й класс — буква Z.  \n",
    "\n",
    "\n",
    "Ваша задача — обучить нейронную сеть и с ее помощью предсказать метки классов для изображений из файла _images_sub.npy_, в нем 50 тысяч изображений. Посмотрите на структуру файла _sample_submission.csv_ — он не содержит полезных данных, а лишь описывает формат, в котором вы загружаете ваши предсказания на сайт. Создайте из ваших предсказаний такой же файл и загрузите в качестве вашего ответа (сабмита). Вы можете делать до 20 сабмитов в сутки.\n",
    "Метрика лидерборда — __accuracy__, то есть доля правильно распознанных изображений.\n",
    "  \n",
    "Задача будет считаться решенной, если в Public Leaderboard вы наберете score, который будет равен или больше __0.82__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734ab908",
   "metadata": {},
   "source": [
    "# Dataset Description\n",
    "\n",
    "`images.npy` - изображения для обучения\n",
    "`labels.npy` - метки для обучения\n",
    "`sample_submission.csv` - формат файла для сабмита\n",
    "`images_sub.npy` - изображения для сабмита\n",
    "Файлы `.npy` - это сохраненные numpy-массивы. Их можно загрузить с помощью функции `np.load(filename)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "424ce8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccfe9801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images.shape = (20000, 48, 48, 3)\n",
      "labels.shape = (20000,)\n"
     ]
    }
   ],
   "source": [
    "# Загрузка данных\n",
    "images = np.load('../mds-misis-dl-captchan/images.npy')\n",
    "labels = np.load('../mds-misis-dl-captchan/labels.npy')\n",
    "\n",
    "print(f'{images.shape = }') if images.size != 0 else print('images не загружен')\n",
    "print(f'{labels.shape = }') if labels.size != 0 else print('labels не загружен')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31fd1349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сразу нормализуем данные\n",
    "images_norm = images / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8255de40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Объекты для обучения созданы успешно!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Преобразование данных в тензор\n",
    "    X = torch.tensor(images_norm,dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "    y = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    # Стандартизируем данные:\n",
    "    # Значения для нормализации\n",
    "    mean = torch.tensor([0.5, 0.5, 0.5])\n",
    "    std = torch.tensor([0.5, 0.5, 0.5])\n",
    "\n",
    "    X = (X - mean[None, :, None, None]) / std[None, :, None, None]\n",
    "\n",
    "    # Разбиваем данные на тренировочную и тестовую выборки\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Создаём датасеты для работы с pytorch\n",
    "    train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "    test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "\n",
    "    # Разбиваем датасеты на батчи\n",
    "    train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    print('Объекты для обучения созданы успешно!')\n",
    "except Exception as e:\n",
    "    print(f'Не удалось сформировать объекты для обучения: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b87f0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Переносим вычисления на gpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using {device} device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d6c6b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=6912, out_features=4096, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=2048, out_features=26, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Базовая нейронная сеть\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(48*48*3, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 26)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae74747c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (conv_stack): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (linear_stack): Sequential(\n",
      "    (0): Linear(in_features=4608, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=26, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Пишем свёрточную нейроннуя сеть\n",
    "class ConvNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.conv_stack = nn.Sequential(\n",
    "            # Из 3-х каналов делаем 32 фильтра\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            # Уменьшаем размерность данных до 24*24\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            # 32 -> 64 фильтра\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            # Уменьшаем размерность до 12*12\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            # 64 -> 128 фильтров\n",
    "            nn.Conv2d(64, 128 ,kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            # Размерность 12*12 -> 6*6\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.linear_stack = nn.Sequential(\n",
    "            # Входной массив 128 фильтров для матрицы 6*6\n",
    "            nn.Linear(128*6*6, 512),\n",
    "            nn.ReLU(),\n",
    "            # Регуляризация\n",
    "            nn.Dropout(0.3),\n",
    "            # Целевой размер - 26 по количеству таргетных лейблов (букв)\n",
    "            nn.Linear(512, 26)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_stack(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "model = ConvNeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eaaad771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "\n",
    "    # Итерируемся по батчам даталоадера\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Переносим данные на gpu\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        # Вычисляем градиенты по отношению к параметрам модели\n",
    "        loss.backward()\n",
    "        # Обнуляем градиенты для следующего шага\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Логируем процесс обучения каждые 100 батчей\n",
    "        # if batch % 100 == 0:\n",
    "        #     loss, curr = loss.item(), (batch + 1) * len(X)\n",
    "        #     print(f'loss = {loss:>7f} [{curr:>5d}/{size:>5d}]')\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Отключаем вычисление градиентов\n",
    "    with torch.no_grad():\n",
    "        # Итерируемся по батчам тестовых данных\n",
    "        for X, y in dataloader:\n",
    "            # Переносим данные на gpu\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_pred = model(X)\n",
    "            test_loss += loss_fn(y_pred, y).item()\n",
    "            correct += (y_pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    # Средний loss на тестовых данных\n",
    "    test_loss /= num_batches\n",
    "    # Общее количество верных предсказаний\n",
    "    accuracy = correct / size\n",
    "\n",
    "    print(f'Test error:\\n\\tAccuracy: {(accuracy * 100):>0.1f}%,\\n\\tAvg loss: {test_loss:>8f}')\n",
    "\n",
    "    # Возвращаем accuracy для дальнейшего сохранения лучшей модели\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89fa07fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      " ====================\n",
      "Test error:\n",
      "\tAccuracy: 83.1%,\n",
      "\tAvg loss: 0.882065\n",
      "Сохранена модель с лучшим accuracy: 83.1%\n",
      "Epoch 2\n",
      " ====================\n",
      "Test error:\n",
      "\tAccuracy: 81.5%,\n",
      "\tAvg loss: 0.933313\n",
      "Epoch 3\n",
      " ====================\n",
      "Test error:\n",
      "\tAccuracy: 83.0%,\n",
      "\tAvg loss: 0.903506\n",
      "Epoch 4\n",
      " ====================\n",
      "Test error:\n",
      "\tAccuracy: 82.4%,\n",
      "\tAvg loss: 0.891160\n",
      "Epoch 5\n",
      " ====================\n",
      "Test error:\n",
      "\tAccuracy: 82.2%,\n",
      "\tAvg loss: 0.953009\n",
      "Epoch 6\n",
      " ====================\n",
      "Test error:\n",
      "\tAccuracy: 82.6%,\n",
      "\tAvg loss: 0.914104\n",
      "Epoch 7\n",
      " ====================\n",
      "Test error:\n",
      "\tAccuracy: 82.2%,\n",
      "\tAvg loss: 0.941656\n",
      "Epoch 8\n",
      " ====================\n",
      "Test error:\n",
      "\tAccuracy: 82.8%,\n",
      "\tAvg loss: 0.910129\n",
      "Epoch 9\n",
      " ====================\n",
      "Test error:\n",
      "\tAccuracy: 83.1%,\n",
      "\tAvg loss: 0.912534\n",
      "Сохранена модель с лучшим accuracy: 83.1%\n",
      "Epoch 10\n",
      " ====================\n",
      "Test error:\n",
      "\tAccuracy: 83.9%,\n",
      "\tAvg loss: 0.861640\n",
      "Сохранена модель с лучшим accuracy: 83.9%\n",
      "Epoch 11\n",
      " ====================\n",
      "Test error:\n",
      "\tAccuracy: 82.8%,\n",
      "\tAvg loss: 0.898419\n",
      "Epoch 12\n",
      " ====================\n",
      "Test error:\n",
      "\tAccuracy: 83.3%,\n",
      "\tAvg loss: 0.893004\n",
      "Epoch 13\n",
      " ====================\n",
      "Test error:\n",
      "\tAccuracy: 82.6%,\n",
      "\tAvg loss: 0.951562\n",
      "Epoch 14\n",
      " ====================\n",
      "Test error:\n",
      "\tAccuracy: 83.3%,\n",
      "\tAvg loss: 0.899114\n",
      "Epoch 15\n",
      " ====================\n",
      "Test error:\n",
      "\tAccuracy: 83.0%,\n",
      "\tAvg loss: 0.930114\n",
      "Epoch 16\n",
      " ====================\n",
      "Test error:\n",
      "\tAccuracy: 82.7%,\n",
      "\tAvg loss: 0.972420\n",
      "Epoch 17\n",
      " ====================\n",
      "Test error:\n",
      "\tAccuracy: 82.8%,\n",
      "\tAvg loss: 0.925630\n",
      "Epoch 18\n",
      " ====================\n",
      "Test error:\n",
      "\tAccuracy: 82.3%,\n",
      "\tAvg loss: 0.945221\n",
      "Epoch 19\n",
      " ====================\n",
      "Test error:\n",
      "\tAccuracy: 82.7%,\n",
      "\tAvg loss: 0.982300\n",
      "Epoch 20\n",
      " ====================\n",
      "Test error:\n",
      "\tAccuracy: 83.1%,\n",
      "\tAvg loss: 0.944373\n",
      "Epoch 21\n",
      " ====================\n",
      "Test error:\n",
      "\tAccuracy: 82.7%,\n",
      "\tAvg loss: 0.949535\n",
      "Ранняя остановка на 21 эпохе\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Параметры для информативного сохранения модели\n",
    "checkpoint = {\n",
    "    'epoch': epoch + 1,\n",
    "    'state_dict': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "    'best_accuracy': best_accuracy\n",
    "}\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.5)\n",
    "\n",
    "# Обучим модель на 50 эпохах + сохраним лучшую модель\n",
    "num_epochs = 50\n",
    "best_accuracy = 0.0\n",
    "patience = 10\n",
    "counter = 0\n",
    "best_model_path = 'best_model.pth'\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Обучение\n",
    "    print(f'Epoch {epoch + 1}\\n', '='*20)\n",
    "    train(train_data_loader, model, loss_fn, optimizer)\n",
    "    accuracy = test(test_data_loader, model, loss_fn)\n",
    "\n",
    "    # Сохраним лучшую модель\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        counter = 0\n",
    "        torch.save(checkpoint, best_model_path)\n",
    "        print(f'Сохранена модель с лучшим accuracy: {best_accuracy * 100:.1f}%')\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "    # Ранняя остановка, если модель долго не улучшает точность\n",
    "    if counter > patience:\n",
    "        print(f'Ранняя остановка на {epoch + 1} эпохе')\n",
    "        break\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e329a4f",
   "metadata": {},
   "source": [
    "# Предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23ee7ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 48, 48, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка данных для предсказания\n",
    "data = np.load('../mds-misis-dl-captchan/images_sub.npy')\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e2a9834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализуем и стандартизируем данные\n",
    "data_norm = data / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "534614ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем в тензор и стандартизируем\n",
    "test_X = torch.tensor(data_norm, dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "\n",
    "mean = torch.tensor([0.5, 0.5, 0.5])\n",
    "std = torch.tensor([0.5, 0.5, 0.5])\n",
    "\n",
    "test_X = (test_X - mean[None, :, None, None]) / std[None, :, None, None]\n",
    "\n",
    "# Преобразуем в torch датасет и даталоадер\n",
    "subm_dataset = torch.utils.data.TensorDataset(test_X)\n",
    "subm_data_loader = torch.utils.data.DataLoader(subm_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49e8f9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Успешно загружена модель с заявленной accuracy: 0.8315\n"
     ]
    }
   ],
   "source": [
    "# Загрузим модель\n",
    "try:\n",
    "    best_model = torch.load('best_model.pth', map_location=device)\n",
    "    model.load_state_dict(best_model['state_dict'])\n",
    "    model.eval()\n",
    "    print(f'Успешно загружена модель с заявленной accuracy: {best_model['best_accuracy']}')\n",
    "except Exception as e:\n",
    "    print('Не удалось загрузить модель')\n",
    "    print(f'Ошибка: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1812382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение предсказаний\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in subm_data_loader:\n",
    "        X = batch[0].to(device)\n",
    "        outputs = model(X)\n",
    "        preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "        predictions.extend(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c58cd10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2)\n"
     ]
    }
   ],
   "source": [
    "# Формирование массива Id,Category\n",
    "ids = np.arange(len(predictions))\n",
    "results = np.column_stack((ids, predictions))\n",
    "print(results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee41d867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предсказания сохранены в файл submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Сохраним результаты в .csv\n",
    "results_df = pd.DataFrame(results, columns=['Id', 'Category'])\n",
    "results_df.to_csv('submission.csv', index=False)\n",
    "print('Предсказания сохранены в файл submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "381cb185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>49995</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>49996</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>49997</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>49998</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>49999</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id  Category\n",
       "0          0        19\n",
       "1          1         2\n",
       "2          2        14\n",
       "3          3        12\n",
       "4          4        10\n",
       "...      ...       ...\n",
       "49995  49995         5\n",
       "49996  49996        10\n",
       "49997  49997        14\n",
       "49998  49998         3\n",
       "49999  49999        25\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
